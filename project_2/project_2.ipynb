{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro ML - Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('train_features.csv')\n",
    "labels = pd.read_csv('train_labels.csv')\n",
    "test_data = pd.read_csv('test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_features(data, n_samples):\n",
    "    x = []\n",
    "    features = [np.nanmedian, np.nanmean, np.nanvar, np.nanmin,\n",
    "           np.nanmax]\n",
    "    for index in range(int(data.shape[0] / n_samples)):\n",
    "        assert data[n_samples * index, 0] == data[n_samples * (index + 1) - 1, 0], \\\n",
    "        'Ids are {}, {}'.format(data[n_samples * index, 0], data[n_samples * (index + 1) - 1, 0])\n",
    "        patient_data = data[n_samples * index:n_samples * (index + 1), 2:]\n",
    "        feature_values = np.empty((len(features), data[:, 2:].shape[1]))\n",
    "        for i, feature in enumerate(features):\n",
    "            feature_values[i] = feature(patient_data, axis=0)\n",
    "        x.append(feature_values.ravel())\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yardenas/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:3405: RuntimeWarning: All-NaN slice encountered\n",
      "  r = func(a, **kwargs)\n",
      "/home/yardenas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Mean of empty slice\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/yardenas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/yardenas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: All-NaN slice encountered\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "x_train = calculate_time_features(train_data.to_numpy(), 12)\n",
    "x_test = calculate_time_features(test_data.to_numpy(), 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Pipeline - Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask1_labels_ids = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "         'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', \n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "y_train = labels[subtask1_labels_ids].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   18.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.928, standard deviation is 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   16.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.797, standard deviation is 0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.741, standard deviation is 0.003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.746, standard deviation is 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.742, standard deviation is 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.805, standard deviation is 0.007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.893, standard deviation is 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.830, standard deviation is 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.738, standard deviation is 0.013\n",
      "Cross-validation score is 0.931, standard deviation is 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "    cross_val_score, KFold)\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# TODO (yarden):\n",
    "# feature selection.\n",
    "# parameters tuning (subsample, learning rate).\n",
    "for i, label in enumerate(subtask1_labels_ids):\n",
    "    pipeline = make_pipeline(\n",
    "                        SimpleImputer(strategy='median'),\n",
    "                        StandardScaler(),\n",
    "                        HistGradientBoostingClassifier())\n",
    "    scores = cross_val_score(pipeline, x_train, y_train[:, i],\n",
    "                                cv=5,\n",
    "                                scoring='roc_auc',\n",
    "                                verbose=True)\n",
    "    print(\"Cross-validation score is {score:.3f},\"\n",
    "          \" standard deviation is {err:.3f}\"\n",
    "          .format(score = scores.mean(), err = scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9774876511563632\n",
      "Training score: 0.9877754029147892\n",
      "Training score: 0.913489343171739\n",
      "Training score: 0.9143622734156679\n",
      "Training score: 0.9144603377463604\n",
      "Training score: 0.9393476707020331\n",
      "Training score: 0.9885212856239103\n",
      "Training score: 0.9409339146555109\n",
      "Training score: 0.9993110535042855\n",
      "Training score: 0.9988747804556561\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'pid': test_data.iloc[0::12, 0].values})\n",
    "for i, label in enumerate(subtask1_labels_ids):\n",
    "    pipeline = pipeline.fit(x_train, y_train[:, i].ravel())\n",
    "    print(\"Training score:\", metrics.roc_auc_score(y_train[:, i], pipeline.predict_proba(x_train)[:, 1]))\n",
    "    predictions = pipeline.predict_proba(x_test)[:, 1]\n",
    "    df[label] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Pipeline - Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask2_labels_ids = ['LABEL_Sepsis']\n",
    "y_train = labels[subtask2_labels_ids].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.699, standard deviation is 0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   17.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "    cross_val_score, KFold)\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# TODO (yarden):\n",
    "# feature selection.\n",
    "# parameters tuning (subsample, learning rate).\n",
    "pipeline = make_pipeline(\n",
    "                    SimpleImputer(strategy='median'),\n",
    "                    StandardScaler(),\n",
    "                    HistGradientBoostingClassifier())\n",
    "\n",
    "scores = cross_val_score(pipeline, x_train, y_train,\n",
    "                            cv=5,\n",
    "                            scoring='roc_auc',\n",
    "                            verbose=True)\n",
    "print(\"Cross-validation score is {score:.3f},\"\n",
    "      \" standard deviation is {err:.3f}\"\n",
    "      .format(score = scores.mean(), err = scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.988209866581915\n"
     ]
    }
   ],
   "source": [
    "pipeline = pipeline.fit(x_train, y_train)\n",
    "predictions = pipeline.predict_proba(x_test)[:, 1]\n",
    "print(\"Training score:\", metrics.roc_auc_score(y_train, pipeline.predict_proba(x_train)[:, 1]))\n",
    "df[subtask2_labels_ids[0]] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Pipeline - Subtask 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask3_labels_ids = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2',\n",
    "                      'LABEL_Heartrate']\n",
    "y_train = labels[subtask3_labels_ids].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.416, standard deviation is 0.008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.616, standard deviation is 0.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score is 0.380, standard deviation is 0.022\n",
      "Cross-validation score is 0.637, standard deviation is 0.012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import (GridSearchCV,\n",
    "    cross_val_score, KFold)\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "for i, label in enumerate(subtask3_labels_ids):\n",
    "    pipeline = make_pipeline(\n",
    "                        SimpleImputer(strategy='median'),\n",
    "                        HistGradientBoostingRegressor(max_depth=3))\n",
    "    scores = cross_val_score(pipeline, x_train, y_train[:, i],\n",
    "                            cv=5,\n",
    "                            scoring='r2',\n",
    "                            verbose=True)\n",
    "    print(\"Cross-validation score is {score:.3f},\"\n",
    "          \" standard deviation is {err:.3f}\"\n",
    "          .format(score = scores.mean(), err = scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.46657876158710565\n",
      "Training score: 0.6432809148552587\n",
      "Training score: 0.4709852855526181\n",
      "Training score: 0.6631141320848979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "for i, label in enumerate(subtask3_labels_ids):\n",
    "    pipeline = make_pipeline(\n",
    "                        SimpleImputer(strategy='median'),\n",
    "                        StandardScaler(),\n",
    "                        HistGradientBoostingRegressor(max_depth=3))\n",
    "    pipeline = pipeline.fit(x_train, y_train[:, i])\n",
    "    predictions = pipeline.predict(x_test)\n",
    "    print(\"Training score:\", metrics.r2_score(y_train[:, i], pipeline.predict(x_train)))\n",
    "    df[label] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prediction.csv', index=False, float_format='%.4f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
