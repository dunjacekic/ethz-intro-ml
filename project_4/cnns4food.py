# -*- coding: utf-8 -*-
"""cnns4food.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/yardenas/ethz-intro-ml/blob/master/project_4/cnns4food.ipynb

# Project 4 - Food Classification using CNNs
``` <Explain what's going on here> ```

https://www.tensorflow.org/tutorials/images/cnn
"""

import tensorflow as tf
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split



"""# Import dataset"""



folder = ''
samples = 'train_triplets.txt'
with open(samples, 'r') as file:
  triplets = [line for line in file.readlines()]
train_samples, val_samples = train_test_split(triplets, test_size=0.2)

with open('val_samples.txt', 'w') as file:
  for item in val_samples:
    flip = np.random.binomial(size=1, n=1, p=0.5)
    sample = item.rstrip() + ' '  + str(flip[0]) + '\n'
    file.write(sample)

with open('train_samples.txt', 'w') as file:
  for item in train_samples:
    flip = np.random.binomial(size=1, n=1, p=0.5)
    sample = item.rstrip() + ' ' + str(flip[0]) + '\n'
    file.write(sample)


IMG_WIDTH = 32
IMG_HEIGHT = 32
def load_image(img):
  # convert the compressed string to a 3D uint8 tensor
  img = tf.image.decode_jpeg(img, channels=3)
  # Use `convert_image_dtype` to convert to floats in the [0,1] range.
  img = tf.image.convert_image_dtype(img, tf.float32)
  # resize the image to the desired size.
  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])

def load_triplets(triplet):
  ids = tf.strings.split(
      triplet
  )
  a = load_image(tf.io.read_file(folder + 'food/' + ids[0] + '.jpg'))
  b = load_image(tf.io.read_file(folder + 'food/' + ids[1] + '.jpg'))
  c = load_image(tf.io.read_file(folder + 'food/' + ids[2] + '.jpg'))
  if tf.math.equal(ids[3], '0'):
    return tf.concat([a, b, c], axis=2), [1, 0]
  else:
    tf.debugging.assert_equal(ids[3], '1')
    return tf.concat([a, c, b], axis=2), [0, 1]


def show_batch(image_batch, label_batch):
  fig = plt.figure(figsize=(4, 4))
  for i in range(3):
    a = image_batch[i, :, :, :3]
    b = image_batch[i, :, :, 3:6]
    c = image_batch[i, :, :, 6:9]
    ax = plt.subplot(3, 3, 3 * i + 1)
    plt.imshow(a)
    ax.axis('off')
    ax = plt.subplot(3, 3, 3 * i + 2)
    plt.imshow(b)
    ax.axis('off')
    ax = plt.subplot(3, 3, 3 * i + 3)
    plt.imshow(c)
    ax.axis('off')
  fig.suptitle(str(label_batch[0, ...]) + str(label_batch[1, ...]) + str(label_batch[2, ...]))
  plt.tight_layout()
  plt.show()
  

train_dataset = tf.data.TextLineDataset(
    folder + 'train_samples.txt'
)
train_dataset = train_dataset.map(load_triplets,
                        num_parallel_calls=tf.data.experimental.AUTOTUNE)

val_dataset = tf.data.TextLineDataset(
    folder + 'val_samples.txt'
)

val_dataset = val_dataset.map(load_triplets,
                        num_parallel_calls=tf.data.experimental.AUTOTUNE)


"""## Build the model"""

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 9)))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(2))
model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
train_dataset = train_dataset.shuffle(1024).batch(64).repeat()
val_dataset = val_dataset.batch(64)

image, label = next(iter(train_dataset))
show_batch(image.numpy(), label.numpy())

history = model.fit(train_dataset, steps_per_epoch=100, epochs=10, validation_data=val_dataset)
