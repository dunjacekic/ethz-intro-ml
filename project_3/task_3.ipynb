{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(X):\n",
    "    # Encode sequence with one-hot\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    new_X = list(X.copy().apply(list))\n",
    "\n",
    "    enc.fit(new_X)\n",
    "    enc_X = enc.transform(new_X).toarray()\n",
    "\n",
    "    return enc_X\n",
    "\n",
    "\n",
    "def read_data():\n",
    "\n",
    "    # Read data\n",
    "    train_raw = pd.read_csv('train.csv')\n",
    "    test_raw = pd.read_csv('test.csv')\n",
    "\n",
    "    # Extract data\n",
    "    train_X_raw = train_raw['Sequence']\n",
    "    train_y = torch.tensor(train_raw['Active'])\n",
    "\n",
    "    test_X_raw = test_raw['Sequence']\n",
    "\n",
    "    # Process sequence\n",
    "    train_X = torch.tensor(encode_seq(train_X_raw))\n",
    "    test_X = torch.tensor(encode_seq(test_X_raw))\n",
    "\n",
    "    return train_X, train_y, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using F1 Loss from [this gist](https://gist.github.com/SuperShinyEyes/dcc68a08ff8b615442e3bc6a9b55a354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1_Loss(nn.Module):\n",
    "    '''Calculate F1 score. Can work with gpu tensors\n",
    "    \n",
    "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        `ndim` == 1. epsilon <= val <= 1\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
    "    - http://www.ryanzhang.info/python/writing-your-own-loss-function-module-for-pytorch/\n",
    "    '''\n",
    "    def __init__(self, epsilon=1e-7):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.ndim == 2\n",
    "        assert y_true.ndim == 1\n",
    "        y_true = F.one_hot(y_true, 2).to(torch.float32)\n",
    "        y_pred = F.softmax(y_pred, dim=1)\n",
    "        \n",
    "        tp = (y_true * y_pred).sum(dim=0).to(torch.float32)\n",
    "        tn = ((1 - y_true) * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "        fp = ((1 - y_true) * y_pred).sum(dim=0).to(torch.float32)\n",
    "        fn = (y_true * (1 - y_pred)).sum(dim=0).to(torch.float32)\n",
    "\n",
    "        precision = tp / (tp + fp + self.epsilon)\n",
    "        recall = tp / (tp + fn + self.epsilon)\n",
    "\n",
    "        f1 = 2* (precision*recall) / (precision + recall + self.epsilon)\n",
    "        f1 = f1.clamp(min=self.epsilon, max=1-self.epsilon)\n",
    "        \n",
    "        return 1 - f1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(X, y, lr):\n",
    "    \n",
    "    net = nn.Sequential(nn.Linear(80, 40),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Dropout(0.2),\n",
    "                        nn.Linear(40, 1))\n",
    "    \n",
    "    loss_fn = F1_Loss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.5)\n",
    "    \n",
    "    # Set batch size\n",
    "    batch_size = 100\n",
    "    \n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "    \n",
    "        running_loss = 0.0\n",
    "        for batch_idx in range(X.shape[0] // batch_size):\n",
    "\n",
    "            # Reset gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            y_pred = net(X[batch_size * batch_idx: batch_size * (batch_idx + 1) - 1, :].float())\n",
    "\n",
    "            # Compute loss\n",
    "            loss = loss_fn(y_pred, y[batch_size * batch_idx: batch_size * (batch_idx + 1) - 1])\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 99:    # print every 100 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, batch_idx + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.475\n",
      "[1,   200] loss: 0.475\n",
      "[1,   300] loss: 0.475\n",
      "[1,   400] loss: 0.473\n",
      "[1,   500] loss: 0.474\n",
      "[1,   600] loss: 0.471\n",
      "[1,   700] loss: 0.474\n",
      "[1,   800] loss: 0.473\n",
      "[1,   900] loss: 0.473\n",
      "[1,  1000] loss: 0.473\n",
      "[1,  1100] loss: 0.474\n",
      "[2,   100] loss: 0.475\n",
      "[2,   200] loss: 0.475\n",
      "[2,   300] loss: 0.475\n",
      "[2,   400] loss: 0.473\n",
      "[2,   500] loss: 0.474\n",
      "[2,   600] loss: 0.471\n",
      "[2,   700] loss: 0.474\n",
      "[2,   800] loss: 0.473\n",
      "[2,   900] loss: 0.473\n",
      "[2,  1000] loss: 0.473\n",
      "[2,  1100] loss: 0.474\n",
      "[3,   100] loss: 0.475\n",
      "[3,   200] loss: 0.475\n",
      "[3,   300] loss: 0.475\n",
      "[3,   400] loss: 0.473\n",
      "[3,   500] loss: 0.474\n",
      "[3,   600] loss: 0.471\n",
      "[3,   700] loss: 0.474\n",
      "[3,   800] loss: 0.473\n",
      "[3,   900] loss: 0.473\n",
      "[3,  1000] loss: 0.473\n",
      "[3,  1100] loss: 0.474\n",
      "[4,   100] loss: 0.475\n",
      "[4,   200] loss: 0.475\n",
      "[4,   300] loss: 0.475\n",
      "[4,   400] loss: 0.473\n",
      "[4,   500] loss: 0.474\n",
      "[4,   600] loss: 0.471\n",
      "[4,   700] loss: 0.474\n",
      "[4,   800] loss: 0.473\n",
      "[4,   900] loss: 0.473\n",
      "[4,  1000] loss: 0.473\n",
      "[4,  1100] loss: 0.474\n",
      "[5,   100] loss: 0.475\n",
      "[5,   200] loss: 0.475\n",
      "[5,   300] loss: 0.475\n",
      "[5,   400] loss: 0.473\n",
      "[5,   500] loss: 0.474\n",
      "[5,   600] loss: 0.471\n",
      "[5,   700] loss: 0.474\n",
      "[5,   800] loss: 0.473\n",
      "[5,   900] loss: 0.473\n",
      "[5,  1000] loss: 0.473\n",
      "[5,  1100] loss: 0.474\n",
      "[6,   100] loss: 0.475\n",
      "[6,   200] loss: 0.475\n",
      "[6,   300] loss: 0.475\n",
      "[6,   400] loss: 0.473\n",
      "[6,   500] loss: 0.474\n",
      "[6,   600] loss: 0.471\n",
      "[6,   700] loss: 0.474\n",
      "[6,   800] loss: 0.473\n",
      "[6,   900] loss: 0.473\n",
      "[6,  1000] loss: 0.473\n",
      "[6,  1100] loss: 0.474\n",
      "[7,   100] loss: 0.475\n",
      "[7,   200] loss: 0.475\n",
      "[7,   300] loss: 0.475\n",
      "[7,   400] loss: 0.473\n",
      "[7,   500] loss: 0.474\n",
      "[7,   600] loss: 0.471\n",
      "[7,   700] loss: 0.474\n",
      "[7,   800] loss: 0.473\n",
      "[7,   900] loss: 0.473\n",
      "[7,  1000] loss: 0.473\n",
      "[7,  1100] loss: 0.474\n",
      "[8,   100] loss: 0.475\n",
      "[8,   200] loss: 0.475\n",
      "[8,   300] loss: 0.475\n",
      "[8,   400] loss: 0.473\n",
      "[8,   500] loss: 0.474\n",
      "[8,   600] loss: 0.471\n",
      "[8,   700] loss: 0.474\n",
      "[8,   800] loss: 0.473\n",
      "[8,   900] loss: 0.473\n",
      "[8,  1000] loss: 0.473\n",
      "[8,  1100] loss: 0.474\n",
      "[9,   100] loss: 0.475\n",
      "[9,   200] loss: 0.475\n",
      "[9,   300] loss: 0.475\n",
      "[9,   400] loss: 0.473\n",
      "[9,   500] loss: 0.474\n",
      "[9,   600] loss: 0.471\n",
      "[9,   700] loss: 0.474\n",
      "[9,   800] loss: 0.473\n",
      "[9,   900] loss: 0.473\n",
      "[9,  1000] loss: 0.473\n",
      "[9,  1100] loss: 0.474\n",
      "[10,   100] loss: 0.475\n",
      "[10,   200] loss: 0.475\n",
      "[10,   300] loss: 0.475\n",
      "[10,   400] loss: 0.473\n",
      "[10,   500] loss: 0.474\n",
      "[10,   600] loss: 0.471\n",
      "[10,   700] loss: 0.474\n",
      "[10,   800] loss: 0.473\n",
      "[10,   900] loss: 0.473\n",
      "[10,  1000] loss: 0.473\n",
      "[10,  1100] loss: 0.474\n"
     ]
    }
   ],
   "source": [
    "net = train_NN(train_X, train_y, 0.001)\n",
    "torch.save(net.state_dict(), './model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = net(test_X.float())\n",
    "# test_y.to_csv('output.csv', index=False)\n",
    "np.savetxt('output.csv', test_y.detach().numpy() > 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitdebca7b4722243bf9e6c9f2b5755d93f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
